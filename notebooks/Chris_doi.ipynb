{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this imports all needed notebooks and utils for the below analysis \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sys\n",
    "#sys.path.insert(0,r'c:\\Users\\Niell Lab\\Documents\\GitHub\\freely-moving-saccades-dev')\n",
    "import saccadeAnalysis as sacc\n",
    "\n",
    "import fmEphys as fme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the below cell to create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = fme.find('*fm1_ephys_props.h5', r''#fill in file path to dataset folder between red ticks) if you want to compile a data set for doi experiments rerun this but find 'fm2_ephys_props.h5'\n",
    "                    \n",
    "\n",
    "rec_dict = {} #this chunk creates a dictionary of the compiled recordings through splitting and concatonating \n",
    "for r in recordings:\n",
    "     r_name = os.path.split(r)[1].split('_fm1')[0] \n",
    "     all_rs = fme.find('{}*ephys_props.h5'.format(r_name), r'T:\\Tim\\SCDark_analysis_pipeline') #change file path to match above \n",
    "     rec_dict[r_name] = all_rs\n",
    "\n",
    "data = sacc.stack_dataset(rec_dict) #this saves the stacked dataset set from compiled experiments \n",
    "\n",
    "data = fme.replace_xr_obj(data) \n",
    "\n",
    "_savefile = 'T:\\Tim\\SCDark_analysis_pipeline\\SC_dark.h5' #must end in .h5 #put path to where you want the data saved \n",
    "fme.write_group_h5(data, _savefile) #this writes the data into the above save file \n",
    "#when you run this you should see a list of the experiments that it is combining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this next chunk of code sets up the data path and provides the pickle files for clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'T:/Tim/SCDark_analysis_pipeline/SC_dark.h5' #this needs to be changed to be the same as the savepath above\n",
    "km_model = 'T:/freely_moving_ephys/SC_analysis/KMeans_PSTH_model_062022.pickle' #leave as is, based on V1 clustering\n",
    "pca_model = 'T:/freely_moving_ephys/SC_analysis/PCA_PSTH_model_062022.pickle' #leave as is, based on V1 clustering\n",
    "savepath = 'T:/Tim/SCDark_analysis_pipeline' #change to where you want the data saved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below code chunk will create a gui and ask for you to label the 4 clusters for SC those clusters are as follows: biphasic 1, late 2, early 3, negative 4, unresponsive 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hffm, out ,= sacc.make_hffm_dataset( #this creates the dataset hffm which is where you will be able to access the data from these experiments\n",
    "    savepath=savepath,\n",
    "    session_dict=None,\n",
    "    hffm_path=data_path,\n",
    "    km_model=km_model,\n",
    "    pca_model=pca_model\n",
    ")\n",
    "\n",
    "# when a python dialog box opens, open the file \"KMEANS_RESULTS.png\" written to the savepath,\n",
    "# and enter the appropriate clustering labels according to that .png figure.\n",
    "#if png is not produced as an additional window it can be found in the save path you provided above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now that the clusters are created you can play with the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this line to see the dataframe as a whole \n",
    "hffm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#most of the data you will be using is actually accessible through clustering portion of hffm dataset which is \"out\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mout\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "#most of the data you will be using is actually accessible through clustering portion of hffm dataset which is \"out\"\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we create a series of variables that make it a bit easier for plotting temp sequences\n",
    "temporal_sequence = out['Fm_pref_temseq'] #variable for preferred temp sequence of gaze shift responsive cells in dataset achieved by indexing into out \n",
    "\n",
    "temporal_sequence_nonpref = out['Fm_nonpref_temseq'] #non preferred temp sequences of gaze shift responsive cells\n",
    "\n",
    "latency_resp = out['Fm_latency_unsort'][resp] #this creates a variable of responsive cells that are sorted by their latency to a gaze shift\n",
    "\n",
    "temp_seq_nonpref_unsort = out['Fm_nonpref_temseq_unsort'] #non preferred temp sequences of all cells\n",
    "\n",
    "sorted_resp = resp[np.argsort(latency_resp)] #this variable provides the indices of responsive cells sorted by ascending latency \n",
    "\n",
    "#let me know if you want to look at any of the unresponsive cell activity I can add in the code for that \n",
    "#this same basis can be used for doi responses too by looking for the same info but naming differently ie. temporal_sequence_doi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can start plotting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preferred temp sequence response of cells responsive to gazeshifts pre doi\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4), dpi=300)\n",
    "_im = sacc.plot_PSTH_heatmap(ax, temporal_sequence, cscale=1)\n",
    "ax.set_aspect(4.)\n",
    "plt.colorbar(ax=ax, mappable=_im)\n",
    "plt.xlabel(\"Preferred temporal sequence pre doi\")\n",
    "ax.xaxis.set_label_position(\"top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonpreferred temp sequence response of cells responsive to gazeshifts pre doi \n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4), dpi=300) \n",
    "_im = sacc.plot_PSTH_heatmap(ax, temp_seq_nonpref_unsort[sorted_resp,:], cscale=1) #makes psth heatmap of temp seq of nonpreferred responses organized by ascending latency as established by sorted_resp\n",
    "ax.set_aspect(4.)\n",
    "plt.colorbar(ax=ax, mappable=_im)\n",
    "plt.xlabel(\"Non preferred temporal sequence pre doi\")\n",
    "\n",
    "ax.xaxis.set_label_position(\"top\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These plots create the mean cluster responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster mean plot of preferred gaze shifts\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4), dpi=300)\n",
    "names = ['early','late', 'biphasic','negative'] #names for clusters\n",
    "for count, name in enumerate(names):  #for loop to iterate through calculating each mean/std for each cluster and plot on top of each other\n",
    "    cluster_psths = fme.flatten_series(hffm['pref_gazeshift_psth'][hffm['gazecluster']==name])\n",
    "    clustmean = np.nanmean(cluster_psths,0)\n",
    "    clusterr = np.std(cluster_psths,0)/ np.sqrt(np.size(cluster_psths,0)) #std error for cluster psths \n",
    "    plt.plot(psth_bins, clustmean, '-', linewidth=2, color=colors[name])\n",
    "    plt.fill_between(psth_bins, clustmean-clusterr, clustmean+clusterr,color=colors[name],alpha=0.3)\n",
    "plt.xlim([-0.2,0.4]); plt.ylim([-.6,.6])\n",
    "plt.ylabel('norm. spike rate'); plt.xlabel('time (msec)')\n",
    "ax.vlines(0,-1,1,color='k',linestyle='dashed',linewidth=1)\n",
    "#ax_clusters.set_xticks(np.linspace(-0.2,0.4,4), labels=np.linspace(-200,400,4).astype(int))\n",
    "#ax_clusters.set_yticks(np.linspace(-0.5,0.5,3))\n",
    "plt.xlabel(\"gaze shift\")\n",
    "\n",
    "ax.xaxis.set_label_position(\"top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster mean plots for nonpreffered gaze shift responses pre doi \n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4), dpi=300)\n",
    "names = ['early','late', 'biphasic','negative']\n",
    "for count, name in enumerate(names):\n",
    "    cluster_psths = fme.flatten_series(hffm['nonpref_gazeshift_psth'][hffm['gazecluster']==name])\n",
    "    clustmean = np.nanmean(cluster_psths,0)\n",
    "    clusterr = np.std(cluster_psths,0)/ np.sqrt(np.size(cluster_psths,0))\n",
    "    plt.plot(psth_bins, clustmean, '-', linewidth=2, color=colors[name])\n",
    "    plt.fill_between(psth_bins, clustmean-clusterr, clustmean+clusterr,color=colors[name],alpha=0.3)\n",
    "plt.xlim([-0.2,0.4]); plt.ylim([-.6,.6])\n",
    "plt.ylabel('norm. spike rate'); plt.xlabel('time (msec)')\n",
    "ax.vlines(0,-1,1,color='k',linestyle='dashed',linewidth=1)\n",
    "#ax_clusters.set_xticks(np.linspace(-0.2,0.4,4), labels=np.linspace(-200,400,4).astype(int))\n",
    "#ax_clusters.set_yticks(np.linspace(-0.5,0.5,3))\n",
    "plt.xlabel(\"nonpreffered gaze shift\")\n",
    "\n",
    "ax.xaxis.set_label_position(\"top\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
